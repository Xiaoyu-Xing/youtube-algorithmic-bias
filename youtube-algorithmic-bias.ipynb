{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_Profiles:\n",
    "    # Specify data location, and output location.\n",
    "    def __init__(self, input_path='data', output_path='output'):\n",
    "        '''\n",
    "        Input:\n",
    "            input_path: data dir, default '/data'\n",
    "            output_put: output dir, default '/ouput', make dir if not exists\n",
    "        '''\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        if not os.path.exists(self.input_path):\n",
    "            raise Exception('Input path not found, or /Data folder not exist.')\n",
    "        if not os.path.exists(self.output_path):\n",
    "            os.makedirs(self.output_path)\n",
    "        # Average profile details, keyed with last word of each json profile filename\n",
    "        self.profiles = {}\n",
    "        # Fully normalized profiles based on all the subreddits they have\n",
    "        self.profiles_norm_ratio = {}\n",
    "        # Partially normalized profiles based on top N*diversity subreddits\n",
    "        self.profiles_norm_ratio_N_diversity = {}\n",
    "        # *_dirs are the root directories path for files of profiles, base/related videos\n",
    "        self.profiles_dir, self.videos_base_dir, self.videos_related_dir = '', '', ''\n",
    "        # Names of files are stored separately, used together with dir path above\n",
    "        self.profiles_files, self.videos_base_files, self.videos_related_files = [], [], []\n",
    "        # Profile videos for each profile, keyed with filename of each json base-video filename\n",
    "        # Non-detailed version only contains urls in a List,\n",
    "        # Detailed version, keyed by the url, contains author, timestamp, score, and title.\n",
    "        self.base_videos, self.base_videos_details, self.base_videos_summary = {}, {}, {}\n",
    "        # Extended/related profile videos for each profile, keyed with filename of each json related-video filename\n",
    "        self.related_videos, self.related_videos_details, self.related_videos_summary = {}, {}, {}\n",
    "        # Run to parse the input folder\n",
    "        self._parse_folders()\n",
    "        # Run to generate profile details\n",
    "        self._generate_profiles()\n",
    "        # Profile video upper bound\n",
    "        self.limit = 50\n",
    "\n",
    "    # Parse data folder\n",
    "    def _parse_folders(self):\n",
    "        path = self.input_path\n",
    "        for (cur_dirpath, sub_dirnames, cur_filenames) in os.walk(path):\n",
    "            # Average profile files\n",
    "            if 'profiles' in cur_dirpath:\n",
    "                self.profiles_dir = cur_dirpath\n",
    "                self.profiles_files = cur_filenames\n",
    "            # Base videos, parse json files only\n",
    "            elif 'videos' in cur_dirpath and 'base' in cur_dirpath:\n",
    "                self.videos_base_dir = cur_dirpath\n",
    "                self.videos_base_files = [\n",
    "                    each for each in cur_filenames if 'ndjson' not in each]\n",
    "            # Related videos, parse json files only\n",
    "            elif 'videos' in cur_dirpath and 'related' in cur_dirpath and 'ndjson' not in cur_dirpath:\n",
    "                self.videos_related_dir = cur_dirpath\n",
    "                self.videos_related_files = cur_filenames\n",
    "\n",
    "    # Read json file\n",
    "    def _read_json(self, path):\n",
    "        '''\n",
    "        Input: \n",
    "            path: file path\n",
    "        Return:\n",
    "            json file, lenght, type\n",
    "        '''\n",
    "        with open(path) as f:\n",
    "            jfile = json.load(f)\n",
    "        return jfile, len(jfile), type(jfile)\n",
    "\n",
    "    # Populate profile details\n",
    "    def _generate_profiles(self):\n",
    "        for profile in self.profiles_files:\n",
    "            if 'ndjson' in profile or 'table' in profile:  # Skip ndjson\n",
    "                continue\n",
    "            # Use last word as key\n",
    "            name = os.path.splitext(profile)[0].split('_', 2)[-1]\n",
    "            profile_path = os.path.join(self.profiles_dir, profile)\n",
    "            self.profiles[name] = self._read_json(profile_path)[0]\n",
    "\n",
    "    # Collect all the videos from a json file\n",
    "    def _load_videos(self, file):\n",
    "        '''\n",
    "        Input:\n",
    "            file: json file path\n",
    "        Return:\n",
    "            video list, and detailed video dict keyed with url\n",
    "        '''\n",
    "        videos_short, videos_details = [], []\n",
    "        videos, length, _ = self._read_json(file)\n",
    "        for video in videos:\n",
    "            videos_short.append(video['url'])\n",
    "            details = video.copy()\n",
    "            del details['url']\n",
    "            videos_details.append({video['url']: details})\n",
    "        return videos_short, videos_details\n",
    "\n",
    "    # Collect all the base videos for all profiles\n",
    "    def _build_profiles_base(self):\n",
    "        for file in self.videos_base_files:\n",
    "            path = os.path.join(self.videos_base_dir, file)\n",
    "            v, v_d = self._load_videos(path)\n",
    "            key = os.path.splitext(file)[0]\n",
    "            self.base_videos[key] = v[:self.limit]\n",
    "            self.base_videos_details[key] = v_d[:self.limit]\n",
    "            self.base_videos_summary[key] = len(self.base_videos[key])\n",
    "\n",
    "    # Give data and file_path (need include .json extension), write file, overwrite if exists.\n",
    "    def _write_json(self, data, file):\n",
    "        '''\n",
    "        Input:\n",
    "            data: data to write\n",
    "            file: file path to write\n",
    "        '''\n",
    "        with open(file, 'w') as f:\n",
    "            # Indent will help json viewer properly display the format\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    # Generate files based on the base output\n",
    "    # Only output file will be shuffled is shuffle is True, the class attributes will not be shuffled,\n",
    "    # to prevent uneven shuffle after sampled with related videos\n",
    "    # Turn details False will stop write detailed version of videos\n",
    "    def output_profiles_base(self, shuffle=False, details=True, limit=50):\n",
    "        '''\n",
    "        Input:\n",
    "            shuffle: boolean, whether to shuffle the ourput\n",
    "            details: boolean, whether to output detailed version\n",
    "            limit: int, how many to output\n",
    "        '''\n",
    "        self.limit = limit\n",
    "        # Run to generate base profile videos\n",
    "        self._build_profiles_base()\n",
    "        out_path = self.output_path\n",
    "        for file, videos in self.base_videos.items():\n",
    "            name_base = 'base_videos_' + file + '.json'\n",
    "            data = videos[:]\n",
    "            if shuffle:\n",
    "                random.shuffle(data)\n",
    "            self._write_json(data, os.path.join(out_path, name_base))\n",
    "        self._write_json(self.base_videos_summary,\n",
    "                         os.path.join(out_path, 'base_summary.json'))\n",
    "        if details:\n",
    "            for file, videos in self.base_videos_details.items():\n",
    "                name_base_details = 'base_videos_details_' + file + '.json'\n",
    "                data = videos[:]\n",
    "                if shuffle:\n",
    "                    random.shuffle(data)\n",
    "                self._write_json(data, os.path.join(\n",
    "                    out_path, name_base_details))\n",
    "\n",
    "    # Read a json profile file, output content, lenght, type. For external use.\n",
    "    def read_json(self, file_path):\n",
    "        return self._read_json(file_path)\n",
    "\n",
    "    # Read a json video file, output short list (url only), detailed list. For external use.\n",
    "    def read_videos(self, file_path):\n",
    "        return self._load_videos(file_path)\n",
    "\n",
    "    def _load_related_videos(self, file):\n",
    "        '''\n",
    "        Input:\n",
    "            file: json file path\n",
    "        Return:\n",
    "            video list, and detailed video dict keyed with url\n",
    "        '''\n",
    "        videos_short, videos_details = [], []\n",
    "        videos, length, _ = self._read_json(file)\n",
    "        for video in videos['data']:\n",
    "            videos_short.append(video['url'])\n",
    "            details = video.copy()\n",
    "            del details['url']\n",
    "            videos_details.append({video['url']: details})\n",
    "        return videos_short, videos_details\n",
    "\n",
    "    def _build_profiles_related(self):\n",
    "        for file in self.videos_related_files:\n",
    "            key = os.path.splitext(file)[0]\n",
    "            path = os.path.join(self.videos_related_dir, file)\n",
    "            v, v_d = self._load_related_videos(path)\n",
    "            self.related_videos[key] = v\n",
    "            self.related_videos_details[key] = v_d\n",
    "            self.related_videos_summary[key] = len(self.related_videos[key])\n",
    "\n",
    "    # NOT IN USE: normalize the profile ratios for all subreddits contained.\n",
    "    def _normalize_profile_ratios(self):\n",
    "        for profile_name, details in self.profiles.items():\n",
    "            total = sum([float(v['ratio']) for v in details.values()])\n",
    "            print(profile_name, total)\n",
    "            self.profiles_norm_ratio[profile_name] = {\n",
    "                k: float(v['ratio']) / total for k, v in details.items()}\n",
    "\n",
    "    # Normalize profile ratios only for top N subreditts.\n",
    "    # N is the \"diversity\" determined by base video numbers, read from base_summary\n",
    "    # Must run output_profile_base first!\n",
    "    def _normalize_profile_ratios_N_diversity(self, diversity_ratio):\n",
    "        for profile_name, details in self.profiles.items():\n",
    "            N = round(self.base_videos_summary[profile_name] * diversity_ratio)\n",
    "            temp = sorted([(k, float(v['ratio'])) for k, v in details.items()], key=lambda x: x[1], reverse=True\n",
    "                          )[:N]\n",
    "            total = sum([each[1] for each in temp])\n",
    "            self.profiles_norm_ratio_N_diversity[profile_name] = [\n",
    "                (each[0], round(each[1] / total * N)) for each in temp]\n",
    "\n",
    "    # First method to implement the extended file:\n",
    "    # Each profile consists of: 1) base profile #: max(videos_in_base_profile, top_LIMIT_in_base_profile)\n",
    "    # 2) N*# of extended videos from subreddits by <1> normalize ratios for each subreddits for top LIMIT videos\n",
    "    # <2> total # of extended videos (roughly) equals to # of base profile, choose top N videos calculated by ratioï¼Œ\n",
    "    # rounded up/down to whole number\n",
    "    def output_profiles_related(self, shuffle=False, diversity_ratio=1):\n",
    "        '''\n",
    "        diversity_ratio: control the ratio of extended videos / base videos numbers\n",
    "        '''\n",
    "        print(\n",
    "            \"*****This step will take long time and large memory, please hold tight!*****\\n\")\n",
    "        sys.stdout.flush()\n",
    "        self._build_profiles_related()\n",
    "        self._normalize_profile_ratios_N_diversity(diversity_ratio)\n",
    "        out_path = self.output_path\n",
    "        summary = {}\n",
    "        summary['diversity_ratio'] = diversity_ratio\n",
    "        for profile_name, details in self.profiles_norm_ratio_N_diversity.items():\n",
    "            short = self.base_videos[profile_name][:]\n",
    "            for subreddit, count in details:\n",
    "                try:\n",
    "                    short.extend(self.related_videos[subreddit][:count])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(\n",
    "                        \"Check related video folder or above subreddit name to match each other.\")\n",
    "            if shuffle:\n",
    "                random.shuffle(short)\n",
    "            summary[profile_name] = len(short)\n",
    "            name_related = 'related_videos_' + profile_name + '.json'\n",
    "            self._write_json(short, os.path.join(out_path, name_related))\n",
    "        self._write_json(summary,\n",
    "                         os.path.join(out_path, 'related_summary.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BP = Build_Profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['enoughtrumpspam', 'feminism', 'incel', 'inceltears', 'mensrights', 'metoo', 'the_donald'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BP.profiles.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BP.output_profiles_base(shuffle=True, details=True, limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****This step will take long time and large memory, please hold tight!*****\n",
      "\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'explainlikeimfive'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Jokes'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'explainlikeimfive'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'tifu'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskWomen'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Jokes'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'tifu'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'explainlikeimfive'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Jokes'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'explainlikeimfive'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Jokes'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'confession'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'relationships'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'AskReddit'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Showerthoughts'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'IAmA'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'LifeProTips'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'Jokes'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'explainlikeimfive'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'personalfinance'\n",
      "Check related video folder or above subreddit name to match each other.\n",
      "'tifu'\n",
      "Check related video folder or above subreddit name to match each other.\n"
     ]
    }
   ],
   "source": [
    "BP.output_profiles_related(shuffle=True, diversity_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
